<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Markov Model on Unladen swallow</title>
    <link>https://blog.owulveryck.info/tags/markov-model.xml</link>
    <description>Recent content in Markov Model on Unladen swallow</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>All rights reserved - 2015/2017</copyright>
    <atom:link href="https://blog.owulveryck.info/tags/markov-model.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Is there a Markov model hidden in the choreography?</title>
      <link>https://blog.owulveryck.info/2016/02/29/is-there-a-markov-model-hidden-in-the-choreography/index.html</link>
      <pubDate>Mon, 29 Feb 2016 20:55:01 +0100</pubDate>
      
      <guid>https://blog.owulveryck.info/2016/02/29/is-there-a-markov-model-hidden-in-the-choreography/index.html</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In my last post I introduced the notion of choreography as a way to deploy an manage application.
It could be possible to implement self-healing, elasticity and in a certain extent
self awareness.&lt;/p&gt;

&lt;p&gt;To do so, we must not rely on the &lt;em&gt;certainty&lt;/em&gt; and the &lt;em&gt;determinism&lt;/em&gt; of the automated tasks.
&lt;em&gt;Mark Burgess&lt;/em&gt; explains in his book &lt;a href=&#34;http://http://www.amazon.com/gp/product/1491923075/ref=pd_lpo_sbs_dp_ss_1?pf_rd_p=1944687522&amp;amp;pf_rd_s=lpo-top-stripe-1&amp;amp;pf_rd_t=201&amp;amp;pf_rd_i=1492389161&amp;amp;pf_rd_m=ATVPDKIKX0DER&amp;amp;pf_rd_r=1BRFTEAZ2RRQ8M77MZ0C&#34;&gt;in search of certainty&lt;/a&gt; that none should consider the command and control anymore.&lt;/p&gt;

&lt;p&gt;Actually we grew up with the idea that a computer will do whatever we told him to.
The truth is that it simply don&amp;rsquo;t. If that sounds astonishing to you, just consider the famous bug.
A bug is a little insect that will avoid any programmed behaviour to act as it should.&lt;/p&gt;

&lt;p&gt;In a lot of wide spread software, we find &lt;em&gt;if-then-else&lt;/em&gt; or &lt;em&gt;try-catch&lt;/em&gt; statements.
Of course one could argue that the purpose of this conditional executionis is to deal with different scenarii, which is true, but indeed,
the keyword is &lt;em&gt;try&lt;/em&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;back-to-the-choreography&#34;&gt;Back to the choreography&lt;/h2&gt;

&lt;p&gt;In the choreography principle, the automation is performed by a set of dancer that acts on their own. Actually, the most logical way
to program it, is to let them know about the execution plan, and assume that everything will run as expected.&lt;/p&gt;

&lt;p&gt;What I would like to study is simply that deployement without knowing the deployement plan.
The nodes would try to perform the task, and depending on the event they receive, they learn and enhance their probability of success.&lt;/p&gt;

&lt;h3 id=&#34;first-problem&#34;&gt;First problem&lt;/h3&gt;

&lt;p&gt;First, I&amp;rsquo;m considering a single node $A$  which can be in three states $\alpha$, $\beta$ and $\gamma$.
Let&amp;rsquo;s $S$ be the set of states such as $S = \left\{\alpha, \beta, \gamma\right\}$&lt;/p&gt;

&lt;h4 id=&#34;actually-knowing-what-s-expected&#34;&gt;Actually knowing what&amp;rsquo;s expected&lt;/h4&gt;

&lt;p&gt;The expected execution is: $ \alpha \mapsto \beta \mapsto \gamma$&lt;/p&gt;

&lt;p&gt;therefore, the transition matrix should be:&lt;/p&gt;

&lt;p&gt;$$
P=\begin{pmatrix}
0 &amp;amp; 1 &amp;amp; 0 \&lt;br /&gt;
0 &amp;amp; 0 &amp;amp; 1 \&lt;br /&gt;
0 &amp;amp; 0 &amp;amp; 0
\end{pmatrix}
$$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s represent it with GNU-R (see &lt;a href=&#34;http://www.r-bloggers.com/getting-started-with-markov-chains/&#34;&gt;this blog post&lt;/a&gt;
for an introduction of markov reprentation with this software)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; library(expm)
&amp;gt; library(markovchain)
&amp;gt; library(diagram)
&amp;gt; library(pracma)
&amp;gt; stateNames &amp;lt;- c(&amp;quot;Alpha&amp;quot;,&amp;quot;Beta&amp;quot;,&amp;quot;Gamma&amp;quot;)
&amp;gt; ExecutionPlan &amp;lt;- matrix(c(0,1,0,0,0,1,0,0,0),nrow=3, byrow=TRUE)
&amp;gt; row.names(ExecutionPlan) &amp;lt;- stateNames; colnames(ExecutionPlan) &amp;lt;- stateNames
&amp;gt; ExecutionPlan
      Alpha Beta Gamma
      Alpha     0    1     0
      Beta      0    0     1
      Gamma     0    0     0
&amp;gt; svg(&amp;quot;ExecutionPlan.svg&amp;quot;)
&amp;gt; plotmat(ExecutionPlan,pos = c(1,2), 
         lwd = 1, box.lwd = 2, 
         cex.txt = 0.8, 
         box.size = 0.1, 
         box.type = &amp;quot;circle&amp;quot;, 
         box.prop = 0.5,
         box.col = &amp;quot;light yellow&amp;quot;,
         arr.length=.1,
         arr.width=.1,
         self.cex = .4,
         self.shifty = -.01,
         self.shiftx = .13,
         main = &amp;quot;&amp;quot;)
&amp;gt; dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which is represented by:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.owulveryck.info/assets/images/ExecutionPlan.svg&#34; alt=&#34;Representation&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;knowing-part-of-the-plan&#34;&gt;Knowing part of the plan&amp;hellip;&lt;/h4&gt;

&lt;p&gt;Now let&amp;rsquo;s consider a different scenario. I assume now that the only known hypothesis is that we cannot go
from $\alpha$ to $\gamma$ and vice-versa, but for the rest, the execution may refer to this transition matrix:&lt;/p&gt;

&lt;p&gt;$
P=\begin{pmatrix}
\frac{1}{2} &amp;amp; \frac{1}{2} &amp;amp; 0 \&lt;br /&gt;
\frac{1}{3} &amp;amp; \frac{1}{3} &amp;amp; \frac{1}{3}  \&lt;br /&gt;
0 &amp;amp; \frac{1}{2} &amp;amp; \frac{1}{2}
\end{pmatrix}
$
which is represented this way &lt;img src=&#34;https://blog.owulveryck.info/assets/images/ExecutionPlan2.svg&#34; alt=&#34;Representation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The transition matrix is regular - we can see, for example that $P^2$ contains all non nil numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; ExecutionPlan %^% 2
                Alpha     Beta      Gamma
          Alpha 0.4166667 0.4166667 0.1666667
          Beta  0.2777778 0.4444444 0.2777778
          Gamma 0.1666667 0.4166667 0.4166667
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Therefore, Makov theorem says that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;as n approaches infinity, $P^n = S$ where $S$ is a matrix of the form $[\mathbf{v}, \mathbf{v},&amp;hellip;,\mathbf{v}]$, where $\mathbf{v}$ being a constant vector&lt;/li&gt;
&lt;li&gt;let $X$ be any state vector, then we have $\lim_{n\to \infty}P^nX = \mathbf{v}$ where $\mathbf{v}$ is a fixed probability vector (the sum of its entries = 1), all whose entries are positives&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we can look for vector $\mathbf{v}$ (also known as the &lt;strong&gt;steady-state vector of the system&lt;/strong&gt;) to see if there is a good chance that our &lt;em&gt;finite state machine&lt;/em&gt; would converged to the desired state $\gamma$.&lt;/p&gt;

&lt;h3 id=&#34;evaluation-of-the-steady-state-vector&#34;&gt;Evaluation of the steady-state vector&lt;/h3&gt;

&lt;p&gt;Now since $P^{n+1}=P*P^n$ and that both $P^{n+1}$ and $P^n$  approach $S$, we have $S=P*S$.&lt;/p&gt;

&lt;p&gt;Note that any column of this matrix equation gives $P\mathbf{v}=\mathbf{v}$. Therefore, the steady-state vector of a regular Markov chain with transition matrix $P$ is the unique probability vector $\mathbf{v}$ satisfying $P\mathbf{v}=\mathbf{v}$.&lt;/p&gt;

&lt;p&gt;To find the steady state vector, we must solve the equation: $P\mathbf{v}=\mathbf{v}$. $\mathbf{v}$ is actually an eigenvector for an eigenvalue $\lambda = 1$.&lt;/p&gt;

&lt;p&gt;_Note from &lt;a href=&#34;https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors&#34;&gt;wikipedia&lt;/a&gt;_&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In linear algebra, an eigenvector or characteristic vector of a square matrix is a vector that does not change its direction under the associated linear transformation.
In other words: if $v$ is a vector that is not zero, then it is an eigenvector of a square matrix $A$ if $Av$ is a scalar multiple of $v$. i
This condition could be written as the equation: $ Av = \lambda v$, where $\lambda$ is a scalar known as the eigenvalue or characteristic
value associated with the eigenvector $v$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To compute the eigenvector, we should find the solution to the equation $det(A-\lambda I)=0$ where $I$ is the identity matrix. Actually
I don&amp;rsquo;t know how to do it anymore, and I will simply use &lt;em&gt;R&lt;/em&gt;&amp;rsquo;s &lt;em&gt;eigen&lt;/em&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; eigen(ExecutionPlan)
$values
[1]  1.0000000  0.5000000 -0.1666667

$vectors
          [,1]          [,2]       [,3]
          [1,] 0.5773503  7.071068e-01  0.5144958
          [2,] 0.5773503  1.107461e-16 -0.6859943
          [3,] 0.5773503 -7.071068e-01  0.5144958

&amp;gt; ExecutionPlan %^% 15
        Alpha      Beta     Gamma
Alpha 0.2857295 0.4285714 0.2856990
Beta  0.2857143 0.4285714 0.2857143
Gamma 0.2856990 0.4285714 0.2857295
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wait, it has found 3 eigenvalues, and one of those equals 1 which is coherent.
But the eigen vector is not coherent at all with the evaluation of the matrix at step 15.&lt;/p&gt;

&lt;p&gt;According to &lt;a href=&#34;http://stackoverflow.com/questions/14912279/how-to-obtain-right-eigenvectors-of-matrix-in-r&#34;&gt;stackoverflow&lt;/a&gt;
that&amp;rsquo;s because it computes the &lt;em&gt;right&lt;/em&gt; eigenvector and what I need is the &lt;em&gt;left&lt;/em&gt; eigenvector.&lt;/p&gt;

&lt;p&gt;Here is how to evaluate it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; lefteigen  &amp;lt;-  function(A){
       return(t(eigen(t(A))$vectors))
}
&amp;gt; lefteigen(ExecutionPlan)
               [,1]          [,2]       [,3]
          [1,] 0.4850713  7.276069e-01  0.4850713
          [2,] 0.7071068 -3.016795e-16 -0.7071068
          [3,] 0.4082483 -8.164966e-01  0.4082483
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have the steady vector : $\mathbf{v} = \begin{pmatrix}0.48 \\ 0.70 \\ 0.40\end{pmatrix}$&lt;/p&gt;

&lt;p&gt;which simply means that according to our theory, our finite state machin will most likely end in state $\beta$.&lt;/p&gt;

&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;

&lt;p&gt;What did I learn ?
Not that much actually. I&amp;rsquo;ve learned that given a transition matrix (a model) I could easily compute the probability of success.
If I consider the finte state machine as the whole automator of deploiement, given the pobability of failure, I can predict
if it&amp;rsquo;s worth continuing the deploiement or not.&lt;/p&gt;

&lt;p&gt;Cool, but far away from my goal: I want a distributed application to learn how to deploy, cure, and take care of itself with a single information:
its topology.&lt;/p&gt;

&lt;p&gt;Back to real life, the model I&amp;rsquo;ve described in this post could be the observable states of the application (eg: $\alpha = initial$,$\beta = configured$, $\gamma=started$&amp;hellip;)&lt;/p&gt;

&lt;p&gt;Hence, the states of the components of the application are hidden from the model (and they must remain hidden, as I don&amp;rsquo;t care observing them)&lt;/p&gt;

&lt;p&gt;And this is the proper definition of a &lt;strong&gt;hidden markov model (HMM)&lt;/strong&gt;.
So yes, there is a Markov model hidden in the choreography!&lt;/p&gt;

&lt;p&gt;I shall continue the study and learn how the signals sent from the compenent gives &lt;em&gt;evidences&lt;/em&gt; and do influence the Markov Model of my application.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a matter of inference, I-maps, Bayesian networks, HMM&amp;hellip;. It&amp;rsquo;s about machine learning which is fascinating !&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>